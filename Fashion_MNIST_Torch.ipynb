{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST_Torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+RYnRMTvNjpHTAoBHl7LC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JerryKurata/colab-pytorch/blob/master/Fashion_MNIST_Torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19Q3hOfO0m97",
        "colab_type": "text"
      },
      "source": [
        "# Fashion-MNIST in Pytorch \n",
        "\n",
        "This notebook demonstrates how we can implement Fashion-MNIST in Pytorch.  This implementation illustrates how we use:\n",
        "\n",
        "\n",
        "*   torch\n",
        "*   torch.nn - Neural Network\n",
        "*   torch.optim - Optimizers\n",
        "*   torchvision - Neural Netwoks for Computer Vision\n",
        "\n",
        "*This code is largely based on this tutorial:https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html* and the code in https://github.com/pytorch/examples/blob/master/mnist/main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2qMBqQp0Wt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "\n",
        "# pyplot is plotting.  numpy is our best friend\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# torch is general torch, torchvision is vision NN layers and utilities\n",
        "#   .transforms is routine that transform vision data\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# We are going to use torch NN libraries, functional API (keras-like), and optimizer\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_zIS4qJYHV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "num_epochs = 25\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKH_xbHaIZbu",
        "colab_type": "text"
      },
      "source": [
        "## Load the Data\n",
        "\n",
        "We first need to load the data.  We could do this from files.  But **torchvision** has a dataset class that supports loading of data for specific well-know models like Fashion-MNIST. And by using this dataset library we do not have to update this code if the data location changes.\n",
        "\n",
        "Notice that we set the batch size in the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5nUYSCM1Oqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transform with to tensor and normalizer.  We normalize each channel\n",
        "#  values to -1.0 to 1.0 via image = (image - mean)/std.  \n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and transform the Fashion-MNIST training and testing datasets\n",
        "train_data = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=True,    # true for training data\n",
        "    transform=transform)\n",
        "test_data = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=False,   # false for test data\n",
        "    transform=transform)\n",
        "\n",
        "# Define Loaders for training and evaluating with the training and test datasets\n",
        "#  num_workers = 2 runs 2 subprocesses to speed the loading\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size= batch_size, \n",
        "                                           shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                           shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um_kyYfg4NDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "a0302200-b3a7-42fb-b0c0-0beefdf650bf"
      },
      "source": [
        "# Define class label names for displaying.  Class labels are [0,1,2,...,9] and these\n",
        "#  labels are match class to position.  So class=0 => 'T-shirt/top', class=1 => 'Trousers'\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "def imshow(img):\n",
        "  np_img = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "  plt.show()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "\n",
        "# Define a helper function to show the image\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:   # do we want grayscale?\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:             # rgb\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "#Display the images from the traning data\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range (batch[0].shape[0]):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(batch[0][i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(int(batch[1][i]))\n",
        "    plt.savefig('digit_mnist.png')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "columns = 4\n",
        "rows = 5\n",
        "for i in range(1, columns*rows +1):\n",
        "    img_xy = np.random.randint(len(train_dataset));\n",
        "    img = train_dataset[img_xy][0][0,:,:]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.title(labels_map[train_dataset[img_xy][1]])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, one_chan cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ba7b3f7bc075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_xy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmatplotlib_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cmap='gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-ba7b3f7bc075>\u001b[0m in \u001b[0;36mmatplotlib_imshow\u001b[0;34m(img, one_channel)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mone_channel\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# do we want grayscale?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Greys\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0;31m# rgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2682\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2683\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2684\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2685\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2686\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28,) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABpCAYAAABRcY8CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAD8klEQVR4nO3Y34sVdRzG8ffT9kNLQ/pBmpUR0cVC\nEgVRFqhhBJHYTURUelHhX1BBBBldKNVdFAVBhAaRUVIglCIVZRcZlDdR9MNYkiS0ZZUsxP10MXNg\n2HbdhWafZHteMHDOmTMz3/Peme/sOaoqYnad8V8P4P8gkQ0S2SCRDRLZIJEN5nxkScOS9knSDN67\nXNLevsfQW2RJBySt6Wt/PXoGeL7aLwSSjk1YTkp6AaCq9gOjktb2OYA5eyZLOlPSEmA1sGPwelUt\nGCzAYuA4sL2z6RvAxl4HU1X/egG2AuPtgI8BjwE3AXuBUeBrYFXn/R/RnGGfAUeBD4GL2nXzgG3A\n4XbbL4BL2nWXAu8BR4DvgUc6+9wEvN1uOwY8DKwHdp9i3BuAHwF1Xlvafo5z+mhTVf1Ebgd3AFjT\nGehh4E6aq+X29vnFncg/ANcA89vnW9p1G4H3gXOBIeAG4Px23SfAS+0f4jrgN+C2TuQTwN3tMecD\nzwEvnmLMe4BNk7w+Bizvq81sTRcPADuramdVjVfVLmAfTfSB16rqu6o6DrzVRqMNdSFwdVWdrKov\nq2pM0uXALcDjVfVnVX0FvEpztg58XlU72mMeBxbRXCn/IGkZsBJ4fZLVR9ttezFbkZcB90gaHSzA\nrcCSznt+7Tz+A1jQPt4KfAC8KemgpGclnUUzVRypqm60n2mumoGRCeP4HVg4xRgfBD6tqp8mWbeQ\nZqrqRZ+Ruz/njQBbq2pRZzmvqrZMu5OqE1X1dFUNAyuAu2jO1oPABZK60a4AfpliDAD7aaakyaxn\nkrNY0lLgbODb6cY6U31GPgRc1T7eBqyVdIekIUnzJK2SdNl0O5G0WtK1koZo5sYTwHhVjdDcSDe3\n+1sOPNQeayq7gOslzZtwjBU0V8D2SbZZCeypqr+mG+tM9Rl5M/BkOzXcC6wDnqC5OY0Aj87weItp\n/ksYA74BPqaZQgDuA66kOavfBZ6qqt1T7aiqDtHc3NZNWLUBeGfC1DNwP/DyDMY5Y6o5/qO9pGGa\naeHGmubDtlfHK1V1c69jmOuRTwdz9hvf6SSRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCR\nDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S\n2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkg\nkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJENEtkgkQ0S2SCRDRLZIJEN\nEtkgkQ0S2SCRDf4GN7MqoduWIjkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9pt-IbVJsVQ",
        "colab_type": "text"
      },
      "source": [
        "## Define the Model\n",
        "\n",
        "We define our model here.  Feel free to experiment with the model structure.  Even a linear model of 2 layers will work with the MNIST data.  But, it probably will not perform that well.  But give it a try!! \n",
        "\n",
        "Notice the forward() method connects each layer to the next.  Read up on nn.Sequeunce and see if that works.  For Keras\n",
        "users, nn.Sequence is like the Keras Sequential modeand this code is like the Keras API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-kLd2c-4yZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Define NN Model class\n",
        "class Model(nn.Module):\n",
        "\n",
        "  # Define the storage for the weights\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  # Hook up the foward pass\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create instance of NN Model\n",
        "model = Model()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5ebr08VUKkD",
        "colab_type": "text"
      },
      "source": [
        "When we train we use the loss criterion to measure loss, and the optimizer method to reduce loss.\n",
        "\n",
        "Our items are one of the 10 classes of fashion items.  CrossEntropyLoss shows how poorly our model is doing at predicting each of the classes.\n",
        "\n",
        "The optimizer will adjust parameters (weights) in the model to minimuze this loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xEbtMXl5v5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss criterion and optimizer method\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtzIcF_lfVlr",
        "colab_type": "text"
      },
      "source": [
        "##  Train the model \n",
        "\n",
        "We calculate a loss for each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL02eYWWfSpu",
        "colab_type": "code",
        "outputId": "6c874ee9-19fa-45c2-e311-e0c9e3adaf08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    num_items = 0\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        num_items += 1\n",
        "        \n",
        "    print('Train Epoch: {}   Loss: {:.6f}'.format(\n",
        "                epoch, running_loss/num_items ))        \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0   Loss: 2.203316\n",
            "Train Epoch: 1   Loss: 0.922050\n",
            "Train Epoch: 2   Loss: 0.691508\n",
            "Train Epoch: 3   Loss: 0.632041\n",
            "Train Epoch: 4   Loss: 0.587824\n",
            "Train Epoch: 5   Loss: 0.546444\n",
            "Train Epoch: 6   Loss: 0.514885\n",
            "Train Epoch: 7   Loss: 0.486205\n",
            "Train Epoch: 8   Loss: 0.468119\n",
            "Train Epoch: 9   Loss: 0.444236\n",
            "Train Epoch: 10   Loss: 0.429095\n",
            "Train Epoch: 11   Loss: 0.413020\n",
            "Train Epoch: 12   Loss: 0.399607\n",
            "Train Epoch: 13   Loss: 0.391053\n",
            "Train Epoch: 14   Loss: 0.379671\n",
            "Train Epoch: 15   Loss: 0.370222\n",
            "Train Epoch: 16   Loss: 0.363817\n",
            "Train Epoch: 17   Loss: 0.357661\n",
            "Train Epoch: 18   Loss: 0.350080\n",
            "Train Epoch: 19   Loss: 0.346251\n",
            "Train Epoch: 20   Loss: 0.337668\n",
            "Train Epoch: 21   Loss: 0.334007\n",
            "Train Epoch: 22   Loss: 0.330064\n",
            "Train Epoch: 23   Loss: 0.322001\n",
            "Train Epoch: 24   Loss: 0.319290\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHPBNVcxgA8u",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the trained model's performance on Testing Data\n",
        "\n",
        "Of course, once we have the model trained, we want to evaluate it's performance. That is why separate training from testing/evaluation data.  And we never train with the testing/evaluation data.\n",
        "\n",
        "So now we will use this testing/evaluation data to see how well our trained model does on data it was **not** trained on.\n",
        "\n",
        "Notice we first use model.eval().  This will model.eval() will notify all layers that you are in eval mode, and that way, batchnorm or dropout layers will work in eval mode instead of training mode.  (https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iNOdI5VgxiT",
        "colab_type": "code",
        "outputId": "a318413a-4244-4117-e674-c2494d71dd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# Evaluate trained model's performance on Testing data\n",
        "  model.eval()          # Set model to evaluation mode\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # Turn off gradient computation\n",
        "    for data, target in test_loader:\n",
        "      output = model(data)\n",
        "      test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -10.3337, Accuracy: 8746/10000 (87%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51LdHAo_niFT",
        "colab_type": "text"
      },
      "source": [
        "## Things to try\n",
        "\n",
        "*   Adjust batch_size and other parameters\n",
        "*   Alter the model with different layers and/or layer parameters \n",
        "*   Add support for GPU\n",
        "*   Replace model definition with nn.Sequential() \n",
        "\n"
      ]
    }
  ]
}